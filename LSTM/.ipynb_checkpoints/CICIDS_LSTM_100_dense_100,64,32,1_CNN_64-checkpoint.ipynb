{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bc719f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\gnssl\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29cccabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "\n",
    "rcParams['figure.figsize'] = 14, 8\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "889411ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:\\dataset\\CIC-IDS-2017\\MachineLearningCVE\\combISCX.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "421df19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Flow Bytes/s\"] = df[\"Flow Bytes/s\"].fillna(df[\"Flow Bytes/s\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2299ee04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Flow Bytes/s\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ae011cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2830743, 79)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "709479b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>...</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60148</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123</td>\n",
       "      <td>99947</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>123</td>\n",
       "      <td>37017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>111161336</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1753752.625</td>\n",
       "      <td>2123197.578</td>\n",
       "      <td>4822992</td>\n",
       "      <td>95</td>\n",
       "      <td>9463032.7</td>\n",
       "      <td>2657727.996</td>\n",
       "      <td>13600000</td>\n",
       "      <td>5700287</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Destination Port   Flow Duration   Total Fwd Packets  \\\n",
       "0                 22             166                   1   \n",
       "1              60148              83                   1   \n",
       "2                123           99947                   1   \n",
       "3                123           37017                   1   \n",
       "4                  0       111161336                 147   \n",
       "\n",
       "    Total Backward Packets  Total Length of Fwd Packets  \\\n",
       "0                        1                            0   \n",
       "1                        2                            0   \n",
       "2                        1                           48   \n",
       "3                        1                           48   \n",
       "4                        0                            0   \n",
       "\n",
       "    Total Length of Bwd Packets   Fwd Packet Length Max  \\\n",
       "0                             0                       0   \n",
       "1                             0                       0   \n",
       "2                            48                      48   \n",
       "3                            48                      48   \n",
       "4                             0                       0   \n",
       "\n",
       "    Fwd Packet Length Min   Fwd Packet Length Mean   Fwd Packet Length Std  \\\n",
       "0                       0                      0.0                     0.0   \n",
       "1                       0                      0.0                     0.0   \n",
       "2                      48                     48.0                     0.0   \n",
       "3                      48                     48.0                     0.0   \n",
       "4                       0                      0.0                     0.0   \n",
       "\n",
       "   ...   min_seg_size_forward  Active Mean   Active Std   Active Max  \\\n",
       "0  ...                     32        0.000        0.000            0   \n",
       "1  ...                     32        0.000        0.000            0   \n",
       "2  ...                     40        0.000        0.000            0   \n",
       "3  ...                     32        0.000        0.000            0   \n",
       "4  ...                      0  1753752.625  2123197.578      4822992   \n",
       "\n",
       "    Active Min  Idle Mean     Idle Std   Idle Max   Idle Min   Label  \n",
       "0            0        0.0        0.000          0          0  BENIGN  \n",
       "1            0        0.0        0.000          0          0  BENIGN  \n",
       "2            0        0.0        0.000          0          0  BENIGN  \n",
       "3            0        0.0        0.000          0          0  BENIGN  \n",
       "4           95  9463032.7  2657727.996   13600000    5700287  BENIGN  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da3c7381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72ac39c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcdac25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution graphs (histogram/bar graph) of column data\n",
    "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):\n",
    "    nunique = df.nunique()\n",
    "    df = df[[col for col in df if nunique[col] > 1 and nunique[col] < 50]] # For displaying purposes, pick columns that have between 1 and 50 unique values\n",
    "    nRow, nCol = df.shape\n",
    "    columnNames = list(df)\n",
    "    nGraphRow = int((nCol + nGraphPerRow - 1) / nGraphPerRow)\n",
    "    plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * nGraphRow), dpi = 80, facecolor = 'w', edgecolor = 'k')\n",
    "    for i in range(min(nCol, nGraphShown)):\n",
    "        plt.subplot(nGraphRow, nGraphPerRow, i + 1)\n",
    "        columnDf = df.iloc[:, i]\n",
    "        if (not np.issubdtype(type(columnDf.iloc[0]), np.number)):\n",
    "            valueCounts = columnDf.value_counts()\n",
    "            valueCounts.plot.bar()\n",
    "        else:\n",
    "            columnDf.hist()\n",
    "        plt.ylabel('counts')\n",
    "        plt.xticks(rotation = 90)\n",
    "        plt.title(f'{columnNames[i]} (column {i})')\n",
    "    plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "plotPerColumnDistribution(df, 79, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acd8218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers(df):\n",
    "    outliers_columns = []\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype != 'object':\n",
    "            std = df[column].std()\n",
    "            if std > 0:\n",
    "                z_score = (df[column] - df[column].mean()) / std\n",
    "                if (np.abs(z_score) > 3).any():\n",
    "                    outliers_columns.append(column)\n",
    "        return outliers_columns\n",
    "\n",
    "outliers_columns = find_outliers(df)\n",
    "print(\"Columns with outliers (3 standard deviations or more away from the mean):\", outliers_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8daa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_invalid_columns(df):\n",
    "    invalid_columns = []\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype != object:  # 문자열이 아닌 경우에만 확인합니다.\n",
    "            if np.any(np.isinf(df[column])) or np.any(np.abs(df[column]) > 1e10 ):\n",
    "                invalid_columns.append(column)\n",
    "    return invalid_columns\n",
    "\n",
    "# 데이터프레임 df에서 불가능한 값을 포함하는 컬럼 찾기\n",
    "invalid_cols = find_invalid_columns(df)\n",
    "\n",
    "if invalid_cols:\n",
    "    print(\"The following columns contain invalid values:\")\n",
    "    print(invalid_cols)\n",
    "else:\n",
    "    print(\"No columns contain invalid values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25f50cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmp = df[\" Destination Port\"]\n",
    "#df = df.drop(columns=\" Destination Port\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba969f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = df.sort_values(by='Flow Bytes/s', ascending=False)\n",
    "print(sorted_df['Flow Bytes/s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b411f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1e8  # 예시 임계값\n",
    "inf_col = ['Flow Bytes/s', ' Flow Packets/s', ' Fwd Header Length', ' Fwd Header Length.1']\n",
    "\n",
    "for col in inf_col:\n",
    "    df[col] = np.clip(df[col], -threshold, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51535157",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Split dataset on train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test=train_test_split(df,test_size=0.3, random_state=10)\n",
    "\n",
    "#Exploratory Analysis\n",
    "# Descriptive statistics\n",
    "train.describe()\n",
    "test.describe()\n",
    "\n",
    "# Packet Attack Distribution\n",
    "train[' Label'].value_counts()\n",
    "test[' Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3756223e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# extract numerical attributes and scale it to have zero mean and unit variance  \n",
    "cols = train.select_dtypes(include=['float64','int64']).columns\n",
    "sc_train = scaler.fit_transform(train.select_dtypes(include=['float64','int64']))\n",
    "sc_test = scaler.fit_transform(test.select_dtypes(include=['float64','int64']))\n",
    "\n",
    "# turn the result back to a dataframe\n",
    "sc_traindf = pd.DataFrame(sc_train, columns = cols)\n",
    "sc_testdf = pd.DataFrame(sc_test, columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7405bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing one hot encoder from sklearn \n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "\n",
    "# creating one hot encoder object \n",
    "onehotencoder = OneHotEncoder() \n",
    "\n",
    "trainDep = train[' Label'].values.reshape(-1,1)\n",
    "trainDep = onehotencoder.fit_transform(trainDep).toarray()\n",
    "testDep = test[' Label'].values.reshape(-1,1)\n",
    "testDep = onehotencoder.fit_transform(testDep).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb28bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X=sc_traindf\n",
    "train_y=trainDep[:,0]\n",
    "\n",
    "test_X=sc_testdf\n",
    "test_y=testDep[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0250b506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming train_X and test_X are your feature matrices, and train_y and test_y are your target vectors\n",
    "\n",
    "# Standardize the data (important before applying PCA)\n",
    "scaler = StandardScaler()\n",
    "train_X_scaled = scaler.fit_transform(train_X)\n",
    "test_X_scaled = scaler.transform(test_X)\n",
    "\n",
    "# Apply PCA\n",
    "num_components = 20  # Use 20 components for PCA\n",
    "pca = PCA(n_components=num_components)\n",
    "\n",
    "# Fit and transform the training data\n",
    "train_X_pca = pca.fit_transform(train_X_scaled)\n",
    "\n",
    "# Transform the testing data (using the same PCA transformation)\n",
    "test_X_pca = pca.transform(test_X_scaled)\n",
    "\n",
    "# Select top 20 features using SelectKBest with the f_classif scoring function\n",
    "feature_selector = SelectKBest(score_func=f_classif, k=20)  # Select top 20 features\n",
    "\n",
    "# Fit and transform the training data\n",
    "train_X_selected = feature_selector.fit_transform(train_X_pca, train_y)\n",
    "\n",
    "# Transform the testing data (using the same feature selection)\n",
    "test_X_selected = feature_selector.transform(test_X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed48e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a021c639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(sequences, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        end_ix = i + n_steps\n",
    "        if end_ix > len(sequences):\n",
    "            break\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41b9954",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = split_sequences(train_X_pca, 5)\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "X_test, y_test = split_sequences(test_X_pca, 5)\n",
    "print(X_test.shape, y_test.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ed3251",
   "metadata": {},
   "source": [
    "y_train_onehot = pd.get_dummies(y_train).values\n",
    "y_test_onehot = pd.get_dummies(y_test).values\n",
    "\n",
    "X_train = tf.constant(X_train, dtype=tf.float32)\n",
    "X_test = tf.constant(X_test, dtype=tf.float32)\n",
    "y_train_onehot = tf.constant(y_train_onehot, dtype=tf.float32)\n",
    "y_test_onehot = tf.constant(y_test_onehot, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab5f53d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Dense, Flatten, Conv1D, MaxPooling1D, LSTM\n",
    "\n",
    "# Assuming train_X_selected and test_X_selected are your selected features after PCA and feature selection\n",
    "\n",
    "# Specify the number of selected features\n",
    "num_selected_features = train_X_selected.shape[1]\n",
    "\n",
    "# Reshape the data for 1D CNN (assuming you have time series-like data)\n",
    "train_X_selected = train_X_selected.reshape(train_X_selected.shape[0], num_selected_features, 1)\n",
    "test_X_selected = test_X_selected.reshape(test_X_selected.shape[0], num_selected_features, 1)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Convolutional layers\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(num_selected_features, 1)))\n",
    "\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(64))\n",
    "\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_X_selected, train_y, epochs=5, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_X_selected, test_y)\n",
    "print(f'Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7d9c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (confusion_matrix, precision_recall_curve, auc,\n",
    "                             roc_curve, recall_score, classification_report, f1_score,\n",
    "                             precision_recall_fscore_support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1b23a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Predict on test set\n",
    "predictions = model.predict(test_X_selected)\n",
    "predictions = (predictions > 0.5)\n",
    "\n",
    "conf_matrix = confusion_matrix(test_y, predictions)\n",
    "TN = conf_matrix[0, 0]  # True Negative\n",
    "FP = conf_matrix[0, 1]  # False Positive\n",
    "TP = conf_matrix[1, 1]  # True Positive\n",
    "FN = conf_matrix[1, 0]  # False Negative\n",
    "\n",
    "# Calculate specificity\n",
    "specificity = TN / (TN + FP)\n",
    "\n",
    "\n",
    "# Calculate additional evaluation metrics\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(test_y, predictions))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(test_y, predictions))\n",
    "\n",
    "print(\"\\nSpecificity:\")\n",
    "print(specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6976ce25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 기존 코드\n",
    "report_dict = classification_report(test_y, predictions, output_dict=True)\n",
    "\n",
    "# 소수점 5자리까지 출력\n",
    "print(\"Classification Report (소수점 5자리):\")\n",
    "for key, value in report_dict.items():\n",
    "    if isinstance(value, dict):\n",
    "        for sub_key, sub_value in value.items():\n",
    "            print(f\"{key} {sub_key}: {sub_value:.5f}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c89e9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa48293",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
